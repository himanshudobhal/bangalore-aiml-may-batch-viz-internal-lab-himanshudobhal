{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2kIWaR5ZpKlJ"
   },
   "source": [
    "## Dog Breed Classification\n",
    "\n",
    "In this we will use Transfer Learning by Inception model with weights pre-trained on Imagenet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F7MDmaAw2xGO"
   },
   "source": [
    "### Load Dataset Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eobbvnFTpgoN"
   },
   "source": [
    "Run the below code to mount the google drive and access the files in drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BZWpQv1OwqYK"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fVhB9OopxFbX"
   },
   "outputs": [],
   "source": [
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1q2zzIaUprk_"
   },
   "source": [
    "Now, upload the given dataset file shared with you in your google drive and give its path for the below given `project_path` variable. For example, a path is given below according to the file path in our google drive. You need to change this to match the path of yours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tp6FvAToxUFs"
   },
   "outputs": [],
   "source": [
    "project_path = \"/content/drive/My Drive/AIML_Labs/Dog_breed/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rydR_j8lqUei"
   },
   "source": [
    "Run the below code to extract all the images in the train.zip and labels.csv.zip files given in the dataset. We are going to use these images as train and validation sets and their labels in further steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3350WZM4w4EL"
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "with ZipFile(project_path+'train.zip', 'r') as z:\n",
    "  z.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_fxzynvB2YCb"
   },
   "outputs": [],
   "source": [
    "# from zipfile import ZipFile\n",
    "# with ZipFile(project_path+'test.zip', 'r') as z:\n",
    "#   z.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4PyTxE8q2jLf"
   },
   "outputs": [],
   "source": [
    "# from zipfile import ZipFile\n",
    "# with ZipFile(project_path+'sample_submission.csv.zip', 'r') as z:\n",
    "#   z.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rXtnEoEixbgi"
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "with ZipFile(project_path+'labels.csv.zip', 'r') as z:\n",
    "  z.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aYmJKmDqqpng"
   },
   "source": [
    "### Read labels.csv file using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QP8YAzQvqyK-"
   },
   "source": [
    "### Print the count of each category of Dogs given in the dataset\n",
    "\n",
    "You can use value_counts() to get the count of each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WI94_Qcc0D4M"
   },
   "source": [
    "### Get one-hot encodings of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCHI6mQTrOZE"
   },
   "source": [
    "### Form feature set using the images in `train` folder and their corresponding labels from `labels.csv`\n",
    "\n",
    "Run the below given code to form the feature set. Here, we are resizing each image to 150x150x3 as the Inception model we will be using in the further steps for transfer learning needs input image in this dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fIdzAwGOz-7w"
   },
   "outputs": [],
   "source": [
    "img_rows=150\n",
    "img_cols=150\n",
    "num_channel=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aC2f9ecR0XGR",
    "outputId": "96d9996a-dddd-4867-a03f-de8c0d1628be"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10222/10222 [00:31<00:00, 320.13it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import cv2\n",
    "x_feature = []\n",
    "y_feature = []\n",
    "\n",
    "i = 0 # initialisation\n",
    "for f, img in tqdm(labels.values): # f for format ,jpg\n",
    "    train_img = cv2.imread('./train/{}.jpg'.format(f),1)\n",
    "    label = one_hot_labels[i]\n",
    "    train_img_resize = cv2.resize(train_img, (img_rows, img_cols)) \n",
    "    x_feature.append(train_img_resize)\n",
    "    y_feature.append(label)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nkkZEpOe0ipk",
    "outputId": "bfabcce8-1929-4ff8-fb21-d6500318c14c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10222, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train_data = np.array(x_feature, np.float32) / 255.   # /= 255 for normolisation\n",
    "print (x_train_data.shape)\n",
    "# x_train_data = np.expand_dims(x_train_data, axis = 3) # for keras to given input to Conv2D layer\n",
    "# print (x_train_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ARn76j3U1CDa",
    "outputId": "02a27532-e683-4c32-959b-2e38b7a2a347"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10222, 120)"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_data = np.array(y_feature)\n",
    "\n",
    "y_train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mEGbyEeor3k_"
   },
   "source": [
    "We have the normalized feature set ready in `x_train_data` and `y_train_data` varaibles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bdCXuAE11gZL"
   },
   "source": [
    "### Split the training and validation data from `x_train_data` and `y_train_data` obtained from above step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XkL-N1jDsU8m"
   },
   "source": [
    "### Import the IncpetionResNetV2 model which we use for Transfer Learning.\n",
    "\n",
    "Run the below code to import the inception model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DnpXdpd9b3E7"
   },
   "outputs": [],
   "source": [
    "from keras.applications import InceptionResNetV2\n",
    "\n",
    "conv_base = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(150,150,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zf7n4WG-b3Hv"
   },
   "outputs": [],
   "source": [
    "#get the length of the train and validation data\n",
    "ntrain = len(x_train)\n",
    "nval = len(x_val)\n",
    "\n",
    "#We will use a batch size of 32. \n",
    "batch_size = 32  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zKezNJVMsocP"
   },
   "source": [
    "### Build the network using above inception model and add layers as mentioned below for classification.\n",
    "\n",
    "1. Add a Dense layer with 256 neurons with `relu` activation\n",
    "\n",
    "2. Add a Dense layer with 120 neurons as final layer (as there are 120 classes in the given dataset) with `softmax` activation for classifiaction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "agJKkc6xtKiq"
   },
   "source": [
    "### Now, freeze the layers in inception model as we dont want to train those layers.\n",
    "\n",
    "Run the below code to freeze the inception model layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "31Mn8qnZb3Ru"
   },
   "outputs": [],
   "source": [
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E4cKw4AjtYtC"
   },
   "source": [
    "### Compile the model using Adam optimizer with `categorical_crossentropy` loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "phXR7HCNtmRi"
   },
   "source": [
    "### Data Augmentation\n",
    "\n",
    "Run the below code to inilialize the ImageDataGenerators for train and validation data separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bqTlW0qHb3Xb"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,   #Scale the image between 0 and 1\n",
    "                                    rotation_range=40,\n",
    "                                    width_shift_range=0.2,\n",
    "                                    height_shift_range=0.2,\n",
    "                                    shear_range=0.2,\n",
    "                                    zoom_range=0.2,\n",
    "                                    horizontal_flip=True,\n",
    "                                    fill_mode='nearest')\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)  #We do not augment validation data. we only perform rescale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6sssbaTfxlkk"
   },
   "source": [
    "### Using the above objects, create the image generators with variable names `train_generator` and `val_generator`\n",
    "\n",
    "You need to use train_datagen.flow() and val_datagen.flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TVFQJZw3x4-C"
   },
   "source": [
    "### Fit the model using fit_generator() using `train_generator` and `val_generator` from the above step with 2 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J1K2MqHbuPUa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TransferLearning_Dog Breed Classification.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
