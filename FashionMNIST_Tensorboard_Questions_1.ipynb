{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FashionMNIST_Tensorboard_Questions-1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "XF0mIIFMPXuo"
      },
      "cell_type": "markdown",
      "source": [
        "## Tensorboard Visualisation of Fashion MNIST dataset"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Bpifh6e2PhLu"
      },
      "cell_type": "markdown",
      "source": [
        "### Import tensorflow and keras and Load the dataset\n",
        "\n",
        "\n",
        "You can directly load Fashion MNIST dataset from tf.keras.datasets similar to MNIST dataset."
      ]
    },
    {
      "metadata": {
        "id": "_u9aKNXWGQEf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.reset_default_graph()\n",
        "tf.set_random_seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vPgaDadtGQEj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9c532cf-1d3f-46b7-9907-acbd39c5c4a0"
      },
      "cell_type": "code",
      "source": [
        "### Collect Data\n",
        "\n",
        "(trainX, trainY),(testX, testY) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "trainX.shape\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "3diiS-AiPhd8"
      },
      "cell_type": "markdown",
      "source": [
        "### Convert Output label to one-hot encodings"
      ]
    },
    {
      "metadata": {
        "id": "0hYc3XJcGQEn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Convert Output label to multiple values\n",
        "trainY = tf.keras.utils.to_categorical(trainY, num_classes=10)\n",
        "testY = tf.keras.utils.to_categorical(testY, num_classes=10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "wG75qPfWPv7j"
      },
      "cell_type": "markdown",
      "source": [
        "### Build the Network based on the infromation given below.\n",
        "\n",
        "2 convolution layers with 32 and 64 filters with relu activation\n",
        "\n",
        "Max Pooling 2x2 filter size\n",
        "\n",
        "flatten\n",
        "\n",
        "Dense layer with 128 neurons with relu activation\n",
        "\n",
        "Dropout p=0.25\n",
        "\n",
        "Dense layer with 10 neurons with softmax activation"
      ]
    },
    {
      "metadata": {
        "id": "QXOEsftKGQEr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Build the Graph\n",
        "\n",
        "tf.keras.backend.clear_session()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rS6tvW_fIoRt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Initialize model, reshape & normalize data\n",
        "model = tf.keras.models.Sequential()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3EqWIkKpIpF6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Reshape data from 2D (28,28) to 3D (28, 28, 1)\n",
        "model.add(tf.keras.layers.Reshape((28,28,1),input_shape=(28,28)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uuFPlLc1KJXs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#normalize data\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "### Apply Convolutional Layers, MaxPooling\n",
        "\n",
        "#Add first convolutional layer\n",
        "model.add(tf.keras.layers.Conv2D(32, #Number of filters \n",
        "                                 kernel_size=(3,3), #Size of the filter\n",
        "                                 activation='relu'))\n",
        "\n",
        "#Add second convolutional layer\n",
        "model.add(tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
        "\n",
        "#Add MaxPooling layer\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "### Add layers for Classification\n",
        "\n",
        "#Flatten the output\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "#Dense layer\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "\n",
        "#Add another dropout layer\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "#Output layer\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Z62ZxIYkUBNP"
      },
      "cell_type": "markdown",
      "source": [
        "### Complie the model with `adam` optimizer and categorical cross entropy loss"
      ]
    },
    {
      "metadata": {
        "id": "j_9HGjSgGQEv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "_8pDLKV8UKj-"
      },
      "cell_type": "markdown",
      "source": [
        "### Run the below command to install tensorboard on Google Colab"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "DnRYDI6SRNxO",
        "outputId": "5c7dcf50-0dce-44ab-91cb-a9706b44e662",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorboardcolab"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "V4p1u_nzUTvF"
      },
      "cell_type": "markdown",
      "source": [
        "### Run the below code to import and initialize the Tensorboard Colab\n",
        "\n",
        "If success, this will generate a link."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "oYZnbebuRSlf",
        "outputId": "0b1526b3-a776-4b38-a02e-0f8307260aac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback\n",
        "\n",
        "tbc = TensorBoardColab()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "http://30a5fe09.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "7sVzXgQ9UkIR"
      },
      "cell_type": "markdown",
      "source": [
        "### Pass **`TensorboardColabCallback(tbc)`** as callback in model.fit and Train the model"
      ]
    },
    {
      "metadata": {
        "id": "vpNP-pM6GQFB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1509
        },
        "outputId": "c87c828b-1e30-4be3-fae1-5a49a7eae143"
      },
      "cell_type": "code",
      "source": [
        "## Train the model\n",
        "\n",
        "#tensorboard = tf.keras.callbacks.TensorBoard(log_dir='/tmp/mnist/cnn_v5')\n",
        "\n",
        "#Train the model\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  sess.run(model.fit(trainX,trainY,          \n",
        "          validation_data=(testX,testY),\n",
        "          callbacks=[TensorBoardColabCallback(tbc)],\n",
        "          epochs=10,\n",
        "          batch_size=32))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 24s 398us/step - loss: 0.1242 - acc: 0.9625 - val_loss: 0.0473 - val_acc: 0.9851\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 22s 361us/step - loss: 0.0469 - acc: 0.9859 - val_loss: 0.0319 - val_acc: 0.9897\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 22s 360us/step - loss: 0.0296 - acc: 0.9909 - val_loss: 0.0446 - val_acc: 0.9857\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 22s 360us/step - loss: 0.0238 - acc: 0.9921 - val_loss: 0.0400 - val_acc: 0.9876\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 22s 360us/step - loss: 0.0171 - acc: 0.9940 - val_loss: 0.0534 - val_acc: 0.9848\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 22s 361us/step - loss: 0.0142 - acc: 0.9955 - val_loss: 0.0319 - val_acc: 0.9907\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 22s 361us/step - loss: 0.0108 - acc: 0.9964 - val_loss: 0.0401 - val_acc: 0.9897\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 22s 359us/step - loss: 0.0100 - acc: 0.9969 - val_loss: 0.0458 - val_acc: 0.9899\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 22s 361us/step - loss: 0.0087 - acc: 0.9972 - val_loss: 0.0484 - val_acc: 0.9901\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 22s 360us/step - loss: 0.0082 - acc: 0.9974 - val_loss: 0.0416 - val_acc: 0.9899\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    299\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[0;32m--> 300\u001b[0;31m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[1;32m    301\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3489\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3490\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3578\u001b[0m       raise TypeError(\"Can not convert a %s into a %s.\" % (type(obj).__name__,\n\u001b[0;32m-> 3579\u001b[0;31m                                                            types_str))\n\u001b[0m\u001b[1;32m   3580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Can not convert a History into a Tensor or Operation.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-179459a535cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensorBoardColabCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtbc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m           batch_size=32))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1137\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \"\"\"\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' % (fetch,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    302\u001b[0m         raise TypeError('Fetch argument %r has invalid type %r, '\n\u001b[1;32m    303\u001b[0m                         \u001b[0;34m'must be a string or Tensor. (%s)'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m                         (fetch, type(fetch), str(e)))\n\u001b[0m\u001b[1;32m    305\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
            "\u001b[0;31mTypeError\u001b[0m: Fetch argument <tensorflow.python.keras.callbacks.History object at 0x7fcf0960ac88> has invalid type <class 'tensorflow.python.keras.callbacks.History'>, must be a string or Tensor. (Can not convert a History into a Tensor or Operation.)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "yA3bisNIPhzI"
      },
      "cell_type": "markdown",
      "source": [
        "A folder with name `Graph` is generated by TensorBoardColab to store the data. Click the above ngork link(in the output of above step) to open **tensorboard**."
      ]
    }
  ]
}